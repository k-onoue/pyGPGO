{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 2.9722],\n",
      "        [-0.6759],\n",
      "        [-4.0022],\n",
      "        [ 2.3119]])\n",
      "\n",
      "[0.10000000149011612, 3.0721945762634277, -0.575851321220398, -3.9021787643432617, 2.411933422088623]\n",
      "[0.19989728927612305, 3.026820659637451, -0.4759327173233032, -3.8022189140319824, 2.5112204551696777]\n",
      "[0.2996184825897217, 2.972748279571533, -0.3761528432369232, -3.702326536178589, 2.60911226272583]\n",
      "[0.39908647537231445, 2.949094295501709, -0.27657124400138855, -3.602529525756836, 2.7047219276428223]\n",
      "[0.4982205629348755, 2.9596242904663086, -0.17724964022636414, -3.5028560161590576, 2.796921491622925]\n",
      "[0.5969364047050476, 2.987581253051758, -0.07825184613466263, -3.403334856033325, 2.884326457977295]\n",
      "[0.6951462030410767, 3.017629861831665, 0.020356416702270508, -3.30399489402771, 2.965325117111206]\n",
      "[0.7927588224411011, 3.0358242988586426, 0.1185075044631958, -3.204864978790283, 3.038179874420166]\n",
      "[0.8896797895431519, 3.0360264778137207, 0.21613208949565887, -3.1059746742248535, 3.101212501525879]\n",
      "[0.9858115911483765, 3.021772861480713, 0.3131592273712158, -3.0073530673980713, 3.153043508529663]\n",
      "[1.0810539722442627, 3.000656843185425, 0.4095165729522705, -2.909029483795166, 3.192810297012329]\n",
      "[1.1753039360046387, 2.9814133644104004, 0.5051304697990417, -2.811033248901367, 3.2202844619750977]\n",
      "[1.268456220626831, 2.971477508544922, 0.599926233291626, -2.7133936882019043, 3.235851764678955]\n",
      "[1.3604036569595337, 2.9735634326934814, 0.6938281655311584, -2.6161394119262695, 3.240387439727783]\n",
      "[1.4510374069213867, 2.985297679901123, 0.7867600321769714, -2.5192995071411133, 3.2350943088531494]\n",
      "[1.5402475595474243, 3.0013654232025146, 0.8786450028419495, -2.4229025840759277, 3.221357583999634]\n",
      "[1.6279233694076538, 3.015427827835083, 0.9694061279296875, -2.3269765377044678, 3.200640916824341]\n",
      "[1.7139540910720825, 3.0222792625427246, 1.0589663982391357, -2.2315495014190674, 3.174424171447754]\n",
      "[1.7982292175292969, 3.0200347900390625, 1.1472491025924683, -2.136648654937744, 3.1441707611083984]\n",
      "[1.8806394338607788, 3.0104827880859375, 1.2341781854629517, -2.0423011779785156, 3.1113121509552]\n",
      "[1.9610768556594849, 2.99784517288208, 1.3196781873703003, -1.948533296585083, 3.077234983444214]\n",
      "[2.039436101913452, 2.9871692657470703, 1.4036750793457031, -1.8553709983825684, 3.043267250061035]\n",
      "[2.115615129470825, 2.982445001602173, 1.4860961437225342, -1.7628395557403564, 3.010655164718628]\n",
      "[2.1895151138305664, 2.984977960586548, 1.5668702125549316, -1.6709637641906738, 2.9805314540863037]\n",
      "[2.261042594909668, 2.9931254386901855, 1.6459285020828247, -1.5797677040100098, 2.953878402709961]\n",
      "[2.330108880996704, 3.003246784210205, 1.723204493522644, -1.4892749786376953, 2.9314897060394287]\n",
      "[2.3966314792633057, 3.0111711025238037, 1.7986342906951904, -1.3995082378387451, 2.9139387607574463]\n",
      "[2.4605352878570557, 3.0138731002807617, 1.872157096862793, -1.3104896545410156, 2.901559591293335]\n",
      "[2.52175235748291, 3.0107009410858154, 1.9437153339385986, -1.222240686416626, 2.8944437503814697]\n",
      "[2.5802230834960938, 3.0034425258636475, 2.0132551193237305, -1.1347819566726685, 2.8924527168273926]\n",
      "[2.635896682739258, 2.9954066276550293, 2.0807268619537354, -1.0481334924697876, 2.89524245262146]\n",
      "[2.688732147216797, 2.990013360977173, 2.1460845470428467, -0.9623144268989563, 2.9022960662841797]\n",
      "[2.7386982440948486, 2.98933482170105, 2.209287166595459, -0.8773432970046997, 2.9129600524902344]\n",
      "[2.785773992538452, 2.9932684898376465, 2.2702980041503906, -0.7932378649711609, 2.9264819622039795]\n",
      "[2.829948902130127, 2.9997494220733643, 2.3290858268737793, -0.7100151181221008, 2.942046880722046]\n",
      "[2.8712234497070312, 3.005760669708252, 2.3856241703033447, -0.6276912689208984, 2.9588122367858887]\n",
      "[2.9096086025238037, 3.0086889266967773, 2.439892053604126, -0.5462818145751953, 2.975942373275757]\n",
      "[2.9451262950897217, 3.0074806213378906, 2.4918739795684814, -0.4658014476299286, 2.9926412105560303]\n",
      "[2.977809190750122, 3.0030179023742676, 2.541559934616089, -0.3862641453742981, 3.0081841945648193]\n",
      "[3.007699966430664, 2.997584819793701, 2.5889456272125244, -0.30768316984176636, 3.0219459533691406]\n",
      "[3.034851551055908, 2.9937515258789062, 2.6340324878692627, -0.2300710380077362, 3.0334250926971436]\n",
      "[3.059326171875, 2.993168354034424, 2.6768274307250977, -0.153439462184906, 3.0422613620758057]\n",
      "[3.081195116043091, 2.9958410263061523, 2.7173430919647217, -0.0777994766831398, 3.048245429992676]\n",
      "[3.1005382537841797, 3.0002410411834717, 2.7555975914001465, -0.0031613558530807495, 3.0513200759887695]\n",
      "[3.1174428462982178, 3.0041275024414062, 2.7916147708892822, 0.0704653188586235, 3.0515739917755127]\n",
      "[3.13200306892395, 3.0056650638580322, 2.8254234790802, 0.143071711063385, 3.049226760864258]\n",
      "[3.144319772720337, 3.0042974948883057, 2.857057809829712, 0.21464967727661133, 3.044609785079956]\n",
      "[3.154498815536499, 3.0009377002716064, 2.88655686378479, 0.28519177436828613, 3.038141965866089]\n",
      "[3.1626508235931396, 2.9974172115325928, 2.91396427154541, 0.3546912372112274, 3.030303478240967]\n",
      "[3.1688902378082275, 2.9955155849456787, 2.9393279552459717, 0.4231420159339905, 3.0216078758239746]\n",
      "[3.1733341217041016, 2.9960620403289795, 2.962700128555298, 0.49053874611854553, 3.0125741958618164]\n",
      "[3.1761021614074707, 2.998573064804077, 2.9841370582580566, 0.5568767189979553, 3.0037012100219727]\n",
      "[3.1773152351379395, 3.0015909671783447, 3.0036978721618652, 0.6221519112586975, 2.9954428672790527]\n",
      "[3.1770949363708496, 3.00350284576416, 3.0214455127716064, 0.6863608956336975, 2.988187313079834]\n",
      "[3.175562620162964, 3.003397226333618, 3.037445306777954, 0.7495009303092957, 2.9822404384613037]\n",
      "[3.1728389263153076, 3.001499652862549, 3.051764965057373, 0.8115699887275696, 2.9778153896331787]\n",
      "[3.1690433025360107, 2.998974561691284, 3.064474582672119, 0.8725665211677551, 2.9750263690948486]\n",
      "[3.164292573928833, 2.9972355365753174, 3.075646162033081, 0.9324896931648254, 2.9738893508911133]\n",
      "[3.1587014198303223, 2.997161626815796, 3.0853524208068848, 0.9913392663002014, 2.974327564239502]\n",
      "[3.152381420135498, 2.9986519813537598, 3.09366774559021, 1.0491156578063965, 2.9761829376220703]\n",
      "[3.145440101623535, 3.0007503032684326, 3.1006669998168945, 1.1058197021484375, 2.9792299270629883]\n",
      "[3.137981414794922, 3.0022356510162354, 3.1064255237579346, 1.1614530086517334, 2.9831931591033936]\n",
      "[3.1301045417785645, 3.002326250076294, 3.111018419265747, 1.216017723083496, 2.9877665042877197]\n",
      "[3.121904134750366, 3.0010900497436523, 3.114521026611328, 1.2695164680480957, 2.9926328659057617]\n",
      "[3.1134696006774902, 2.9993460178375244, 3.1170074939727783, 1.32195246219635, 2.9974825382232666]\n",
      "[3.1048853397369385, 2.998140573501587, 3.118551731109619, 1.373329520225525, 3.0020313262939453]\n",
      "[3.0962300300598145, 2.9981260299682617, 3.1192262172698975, 1.423651933670044, 3.0060348510742188]\n",
      "[3.0875768661499023, 2.9992079734802246, 3.1191022396087646, 1.4729244709014893, 3.009300470352173]\n",
      "[3.078993082046509, 3.000655174255371, 3.1182496547698975, 1.5211526155471802, 3.0116946697235107]\n",
      "[3.070540428161621, 3.0015788078308105, 3.1167361736297607, 1.5683420896530151, 3.0131475925445557]\n",
      "[3.062274694442749, 3.0014729499816895, 3.1146278381347656, 1.6144992113113403, 3.0136518478393555]\n",
      "[3.054245948791504, 3.000490665435791, 3.1119885444641113, 1.6596307754516602, 3.013258695602417]\n",
      "[3.0464982986450195, 2.999303102493286, 3.108879804611206, 1.7037440538406372, 3.012070894241333]\n",
      "[3.0390706062316895, 2.9986519813537598, 3.105360984802246, 1.7468467950820923, 3.0102322101593018]\n",
      "[3.0319957733154297, 2.9988901615142822, 3.1014888286590576, 1.7889471054077148, 3.0079152584075928]\n",
      "[3.025301456451416, 2.9997925758361816, 3.0973172187805176, 1.8300535678863525, 3.0053091049194336]\n",
      "[3.019010305404663, 3.000739336013794, 3.092897415161133, 1.8701751232147217, 3.002605438232422]\n",
      "[3.0131397247314453, 3.001133680343628, 3.088278293609619, 1.9093210697174072, 2.9999868869781494]\n",
      "[3.007702589035034, 3.0007753372192383, 3.083505392074585, 1.947501301765442, 2.997615337371826]\n",
      "[3.0027072429656982, 2.9999582767486572, 3.0786218643188477, 1.984725832939148, 2.995623826980591]\n",
      "[2.998157501220703, 2.9992449283599854, 3.0736677646636963, 2.021005153656006, 2.9941093921661377]\n",
      "[2.994053602218628, 2.99908447265625, 3.0686802864074707, 2.056349992752075, 2.9931299686431885]\n",
      "[2.990391969680786, 2.9995319843292236, 3.0636937618255615, 2.090771436691284, 2.9927031993865967]\n",
      "[2.9871654510498047, 3.000242233276367, 3.0587399005889893, 2.124281167984009, 2.9928088188171387]\n",
      "[2.9843640327453613, 3.0007266998291016, 3.053847312927246, 2.156890630722046, 2.9933922290802]\n",
      "[2.9819748401641846, 3.000685930252075, 3.049042224884033, 2.1886119842529297, 2.9943716526031494]\n",
      "[2.979982852935791, 3.0001940727233887, 3.0443480014801025, 2.2194573879241943, 2.9956448078155518]\n",
      "[2.978370428085327, 2.999619245529175, 3.039785623550415, 2.249439239501953, 2.997098445892334]\n",
      "[2.977118492126465, 2.999354362487793, 3.0353732109069824, 2.2785704135894775, 2.9986159801483154]\n",
      "[2.9762063026428223, 2.9995505809783936, 3.0311267375946045, 2.306864023208618, 3.000086545944214]\n",
      "[2.975611925125122, 3.000033378601074, 3.027059555053711, 2.3343329429626465, 3.0014116764068604]\n",
      "[2.9753122329711914, 3.0004477500915527, 3.0231828689575195, 2.360990524291992, 3.0025112628936768]\n",
      "[2.9752838611602783, 3.0005152225494385, 3.0195059776306152, 2.386850357055664, 3.0033278465270996]\n",
      "[2.9755024909973145, 3.00022029876709, 3.016036033630371, 2.411926031112671, 3.003829002380371]\n",
      "[2.9759438037872314, 2.999800443649292, 3.0127780437469482, 2.4362313747406006, 3.004007339477539]\n",
      "[2.97658371925354, 2.9995598793029785, 3.009735584259033, 2.459780216217041, 3.0038790702819824]\n",
      "[2.977398157119751, 2.9996511936187744, 3.0069103240966797, 2.48258638381958, 3.003480911254883]\n",
      "[2.978363513946533, 2.9999802112579346, 3.0043022632598877, 2.504664182662964, 3.002866268157959]\n",
      "[2.979456663131714, 3.0002918243408203, 3.0019102096557617, 2.5260276794433594, 3.0020995140075684]\n",
      "[2.9806554317474365, 3.0003654956817627, 2.9997315406799316, 2.5466911792755127, 3.001250743865967]\n",
      "各初期点からの最適化結果:\n",
      "Start 1: x = 2.9807, loss = 4.0004\n",
      "Start 2: x = 3.0004, loss = 4.0000\n",
      "Start 3: x = 2.9997, loss = 4.0000\n",
      "Start 4: x = 2.5467, loss = 4.2055\n",
      "Start 5: x = 3.0013, loss = 4.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "# 最小化したい関数\n",
    "def func(x):\n",
    "    return (x - 3) ** 2 + 4\n",
    "\n",
    "# マルチスタートの数と初期点生成\n",
    "n_starts = 5  # マルチスタートの数\n",
    "initial_param = torch.tensor([0.0])  # 指定した初期パラメータ\n",
    "\n",
    "# Sobolエンジンで初期点を生成 (一様分布の区間を [-5, 5] と仮定)\n",
    "sobol_engine = SobolEngine(dimension=1, scramble=True)\n",
    "sobol_points = sobol_engine.draw(n_starts - 1) * 10 - 5\n",
    "\n",
    "print()\n",
    "print(sobol_points)\n",
    "print()\n",
    "\n",
    "# 指定した初期パラメータを追加して初期点リストを作成し、行列化\n",
    "initial_points = torch.cat((initial_param.unsqueeze(0), sobol_points), dim=0).requires_grad_(True)\n",
    "\n",
    "# Adamオプティマイザの設定\n",
    "optimizer = optim.Adam([initial_points], lr=0.1)\n",
    "\n",
    "# 最適化ループ\n",
    "n_steps = 100\n",
    "for step in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = func(initial_points).sum()  # 各初期点での損失を計算し合計\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print([float(point.detach()) for point in initial_points])\n",
    "\n",
    "# 最終結果を表示\n",
    "print(\"各初期点からの最適化結果:\")\n",
    "for i, x_opt in enumerate(initial_points, 1):\n",
    "    final_loss = func(x_opt).item()\n",
    "    print(f\"Start {i}: x = {x_opt.item():.4f}, loss = {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 0.1000, -0.1000]), tensor([-2.0488,  4.1714]), tensor([ 0.4354, -1.0250]), tensor([3.5614, 1.9562]), tensor([-3.7354, -2.9600])]\n",
      "[tensor([ 0.1999, -0.1998]), tensor([-1.9489,  4.0714]), tensor([ 0.5353, -1.1246]), tensor([3.4621, 1.8562]), tensor([-3.6354, -2.8604])]\n",
      "[tensor([ 0.2996, -0.2994]), tensor([-1.8490,  3.9715]), tensor([ 0.6350, -1.2235]), tensor([3.3644, 1.7564]), tensor([-3.5355, -2.7615])]\n",
      "[tensor([ 0.3991, -0.3985]), tensor([-1.7493,  3.8718]), tensor([ 0.7344, -1.3214]), tensor([3.2691, 1.6568]), tensor([-3.4358, -2.6636])]\n",
      "[tensor([ 0.4982, -0.4970]), tensor([-1.6498,  3.7721]), tensor([ 0.8334, -1.4178]), tensor([3.1775, 1.5574]), tensor([-3.3361, -2.5673])]\n",
      "[tensor([ 0.5969, -0.5949]), tensor([-1.5504,  3.6727]), tensor([ 0.9319, -1.5123]), tensor([3.0912, 1.4583]), tensor([-3.2366, -2.4730])]\n",
      "[tensor([ 0.6951, -0.6918]), tensor([-1.4514,  3.5734]), tensor([ 1.0298, -1.6042]), tensor([3.0118, 1.3595]), tensor([-3.1373, -2.3813])]\n",
      "[tensor([ 0.7928, -0.7877]), tensor([-1.3526,  3.4744]), tensor([ 1.1270, -1.6930]), tensor([2.9413, 1.2612]), tensor([-3.0381, -2.2928])]\n",
      "[tensor([ 0.8897, -0.8823]), tensor([-1.2542,  3.3757]), tensor([ 1.2234, -1.7779]), tensor([2.8814, 1.1633]), tensor([-2.9393, -2.2083])]\n",
      "[tensor([ 0.9858, -0.9754]), tensor([-1.1562,  3.2772]), tensor([ 1.3189, -1.8582]), tensor([2.8335, 1.0659]), tensor([-2.8407, -2.1285])]\n",
      "[tensor([ 1.0811, -1.0669]), tensor([-1.0586,  3.1791]), tensor([ 1.4133, -1.9331]), tensor([2.7982, 0.9691]), tensor([-2.7424, -2.0543])]\n",
      "[tensor([ 1.1753, -1.1565]), tensor([-0.9614,  3.0814]), tensor([ 1.5065, -2.0019]), tensor([2.7756, 0.8730]), tensor([-2.6445, -1.9863])]\n",
      "[tensor([ 1.2685, -1.2440]), tensor([-0.8648,  2.9841]), tensor([ 1.5984, -2.0639]), tensor([2.7649, 0.7776]), tensor([-2.5469, -1.9254])]\n",
      "[tensor([ 1.3604, -1.3291]), tensor([-0.7688,  2.8872]), tensor([ 1.6888, -2.1185]), tensor([2.7651, 0.6829]), tensor([-2.4497, -1.8720])]\n",
      "[tensor([ 1.4510, -1.4117]), tensor([-0.6734,  2.7908]), tensor([ 1.7777, -2.1652]), tensor([2.7748, 0.5891]), tensor([-2.3530, -1.8267])]\n",
      "[tensor([ 1.5402, -1.4914]), tensor([-0.5786,  2.6949]), tensor([ 1.8648, -2.2037]), tensor([2.7925, 0.4962]), tensor([-2.2567, -1.7898])]\n",
      "[tensor([ 1.6279, -1.5681]), tensor([-0.4846,  2.5996]), tensor([ 1.9501, -2.2339]), tensor([2.8165, 0.4043]), tensor([-2.1609, -1.7612])]\n",
      "[tensor([ 1.7140, -1.6415]), tensor([-0.3912,  2.5048]), tensor([ 2.0334, -2.2560]), tensor([2.8454, 0.3134]), tensor([-2.0656, -1.7408])]\n",
      "[tensor([ 1.7982, -1.7114]), tensor([-0.2987,  2.4106]), tensor([ 2.1146, -2.2701]), tensor([2.8776, 0.2237]), tensor([-1.9708, -1.7284])]\n",
      "[tensor([ 1.8806, -1.7775]), tensor([-0.2070,  2.3171]), tensor([ 2.1935, -2.2768]), tensor([2.9117, 0.1351]), tensor([-1.8767, -1.7234])]\n",
      "[tensor([ 1.9611, -1.8398]), tensor([-0.1162,  2.2242]), tensor([ 2.2699, -2.2766]), tensor([2.9462, 0.0477]), tensor([-1.7831, -1.7253])]\n",
      "[tensor([ 2.0394, -1.8980]), tensor([-0.0262,  2.1321]), tensor([ 2.3439, -2.2701]), tensor([ 2.9797, -0.0384]), tensor([-1.6901, -1.7333])]\n",
      "[tensor([ 2.1156, -1.9520]), tensor([0.0627, 2.0406]), tensor([ 2.4152, -2.2580]), tensor([ 3.0111, -0.1231]), tensor([-1.5978, -1.7468])]\n",
      "[tensor([ 2.1895, -2.0016]), tensor([0.1507, 1.9500]), tensor([ 2.4837, -2.2412]), tensor([ 3.0392, -0.2064]), tensor([-1.5062, -1.7649])]\n",
      "[tensor([ 2.2610, -2.0467]), tensor([0.2376, 1.8601]), tensor([ 2.5494, -2.2204]), tensor([ 3.0632, -0.2883]), tensor([-1.4153, -1.7868])]\n",
      "[tensor([ 2.3301, -2.0874]), tensor([0.3235, 1.7710]), tensor([ 2.6121, -2.1963]), tensor([ 3.0823, -0.3686]), tensor([-1.3251, -1.8118])]\n",
      "[tensor([ 2.3966, -2.1236]), tensor([0.4082, 1.6828]), tensor([ 2.6717, -2.1699]), tensor([ 3.0961, -0.4473]), tensor([-1.2356, -1.8390])]\n",
      "[tensor([ 2.4605, -2.1553]), tensor([0.4918, 1.5954]), tensor([ 2.7282, -2.1419]), tensor([ 3.1044, -0.5244]), tensor([-1.1469, -1.8675])]\n",
      "[tensor([ 2.5218, -2.1825]), tensor([0.5742, 1.5089]), tensor([ 2.7815, -2.1130]), tensor([ 3.1074, -0.5998]), tensor([-1.0591, -1.8968])]\n",
      "[tensor([ 2.5802, -2.2054]), tensor([0.6554, 1.4234]), tensor([ 2.8315, -2.0839]), tensor([ 3.1054, -0.6734]), tensor([-0.9720, -1.9259])]\n",
      "[tensor([ 2.6359, -2.2240]), tensor([0.7353, 1.3388]), tensor([ 2.8783, -2.0554]), tensor([ 3.0988, -0.7453]), tensor([-0.8858, -1.9543])]\n",
      "[tensor([ 2.6887, -2.2386]), tensor([0.8140, 1.2551]), tensor([ 2.9217, -2.0281]), tensor([ 3.0884, -0.8154]), tensor([-0.8004, -1.9813])]\n",
      "[tensor([ 2.7387, -2.2492]), tensor([0.8914, 1.1725]), tensor([ 2.9619, -2.0025]), tensor([ 3.0749, -0.8836]), tensor([-0.7159, -2.0064])]\n",
      "[tensor([ 2.7858, -2.2562]), tensor([0.9674, 1.0908]), tensor([ 2.9987, -1.9791]), tensor([ 3.0592, -0.9499]), tensor([-0.6323, -2.0291])]\n",
      "[tensor([ 2.8299, -2.2596]), tensor([1.0420, 1.0102]), tensor([ 3.0322, -1.9583]), tensor([ 3.0421, -1.0142]), tensor([-0.5496, -2.0490])]\n",
      "[tensor([ 2.8712, -2.2599]), tensor([1.1153, 0.9307]), tensor([ 3.0626, -1.9405]), tensor([ 3.0246, -1.0766]), tensor([-0.4678, -2.0658])]\n",
      "[tensor([ 2.9096, -2.2571]), tensor([1.1872, 0.8522]), tensor([ 3.0897, -1.9259]), tensor([ 3.0075, -1.1370]), tensor([-0.3870, -2.0794])]\n",
      "[tensor([ 2.9451, -2.2517]), tensor([1.2576, 0.7747]), tensor([ 3.1137, -1.9145]), tensor([ 2.9915, -1.1955]), tensor([-0.3072, -2.0895])]\n",
      "[tensor([ 2.9778, -2.2438]), tensor([1.3266, 0.6984]), tensor([ 3.1347, -1.9065]), tensor([ 2.9774, -1.2518]), tensor([-0.2283, -2.0963])]\n",
      "[tensor([ 3.0077, -2.2338]), tensor([1.3941, 0.6232]), tensor([ 3.1528, -1.9017]), tensor([ 2.9657, -1.3062]), tensor([-0.1504, -2.0999])]\n",
      "[tensor([ 3.0349, -2.2219]), tensor([1.4601, 0.5491]), tensor([ 3.1680, -1.9001]), tensor([ 2.9568, -1.3585]), tensor([-0.0735, -2.1003])]\n",
      "[tensor([ 3.0593, -2.2085]), tensor([1.5246, 0.4762]), tensor([ 3.1806, -1.9014]), tensor([ 2.9508, -1.4088]), tensor([ 0.0024, -2.0978])]\n",
      "[tensor([ 3.0812, -2.1937]), tensor([1.5876, 0.4044]), tensor([ 3.1905, -1.9053]), tensor([ 2.9479, -1.4570]), tensor([ 0.0772, -2.0928])]\n",
      "[tensor([ 3.1005, -2.1779]), tensor([1.6491, 0.3338]), tensor([ 3.1981, -1.9116]), tensor([ 2.9479, -1.5031]), tensor([ 0.1510, -2.0855])]\n",
      "[tensor([ 3.1174, -2.1614]), tensor([1.7090, 0.2644]), tensor([ 3.2033, -1.9198]), tensor([ 2.9506, -1.5472]), tensor([ 0.2238, -2.0764])]\n",
      "[tensor([ 3.1320, -2.1444]), tensor([1.7675, 0.1961]), tensor([ 3.2064, -1.9295]), tensor([ 2.9557, -1.5893]), tensor([ 0.2955, -2.0660])]\n",
      "[tensor([ 3.1443, -2.1271]), tensor([1.8243, 0.1290]), tensor([ 3.2074, -1.9405]), tensor([ 2.9626, -1.6294]), tensor([ 0.3662, -2.0545])]\n",
      "[tensor([ 3.1545, -2.1097]), tensor([1.8796, 0.0632]), tensor([ 3.2067, -1.9522]), tensor([ 2.9709, -1.6675]), tensor([ 0.4358, -2.0424])]\n",
      "[tensor([ 3.1627, -2.0926]), tensor([ 1.9334e+00, -1.4731e-03]), tensor([ 3.2042, -1.9642]), tensor([ 2.9800, -1.7036]), tensor([ 0.5043, -2.0301])]\n",
      "[tensor([ 3.1689, -2.0758]), tensor([ 1.9856, -0.0649]), tensor([ 3.2003, -1.9763]), tensor([ 2.9894, -1.7378]), tensor([ 0.5717, -2.0181])]\n",
      "[tensor([ 3.1733, -2.0595]), tensor([ 2.0363, -0.1271]), tensor([ 3.1949, -1.9879]), tensor([ 2.9985, -1.7700]), tensor([ 0.6380, -2.0066])]\n",
      "[tensor([ 3.1761, -2.0440]), tensor([ 2.0854, -0.1882]), tensor([ 3.1884, -1.9988]), tensor([ 3.0068, -1.8004]), tensor([ 0.7033, -1.9959])]\n",
      "[tensor([ 3.1773, -2.0293]), tensor([ 2.1330, -0.2479]), tensor([ 3.1808, -2.0088]), tensor([ 3.0140, -1.8289]), tensor([ 0.7674, -1.9863])]\n",
      "[tensor([ 3.1771, -2.0155]), tensor([ 2.1791, -0.3065]), tensor([ 3.1723, -2.0176]), tensor([ 3.0198, -1.8556]), tensor([ 0.8305, -1.9781])]\n",
      "[tensor([ 3.1756, -2.0028]), tensor([ 2.2237, -0.3638]), tensor([ 3.1630, -2.0251]), tensor([ 3.0239, -1.8805]), tensor([ 0.8924, -1.9713])]\n",
      "[tensor([ 3.1728, -1.9912]), tensor([ 2.2667, -0.4200]), tensor([ 3.1531, -2.0310]), tensor([ 3.0262, -1.9038]), tensor([ 0.9533, -1.9660])]\n",
      "[tensor([ 3.1690, -1.9808]), tensor([ 2.3083, -0.4749]), tensor([ 3.1427, -2.0354]), tensor([ 3.0268, -1.9253]), tensor([ 1.0130, -1.9624])]\n",
      "[tensor([ 3.1643, -1.9717]), tensor([ 2.3483, -0.5285]), tensor([ 3.1320, -2.0383]), tensor([ 3.0258, -1.9453]), tensor([ 1.0716, -1.9603])]\n",
      "[tensor([ 3.1587, -1.9637]), tensor([ 2.3869, -0.5810]), tensor([ 3.1210, -2.0396]), tensor([ 3.0234, -1.9636]), tensor([ 1.1292, -1.9597])]\n",
      "[tensor([ 3.1524, -1.9571]), tensor([ 2.4241, -0.6322]), tensor([ 3.1099, -2.0396]), tensor([ 3.0197, -1.9805]), tensor([ 1.1856, -1.9606])]\n",
      "[tensor([ 3.1454, -1.9516]), tensor([ 2.4598, -0.6822]), tensor([ 3.0988, -2.0382]), tensor([ 3.0153, -1.9959]), tensor([ 1.2409, -1.9626])]\n",
      "[tensor([ 3.1380, -1.9474]), tensor([ 2.4941, -0.7311]), tensor([ 3.0878, -2.0357]), tensor([ 3.0103, -2.0099]), tensor([ 1.2951, -1.9658])]\n",
      "[tensor([ 3.1301, -1.9443]), tensor([ 2.5271, -0.7787]), tensor([ 3.0770, -2.0322]), tensor([ 3.0052, -2.0225]), tensor([ 1.3483, -1.9698])]\n",
      "[tensor([ 3.1219, -1.9423]), tensor([ 2.5586, -0.8251]), tensor([ 3.0664, -2.0279]), tensor([ 3.0002, -2.0339]), tensor([ 1.4003, -1.9745])]\n",
      "[tensor([ 3.1135, -1.9414]), tensor([ 2.5889, -0.8704]), tensor([ 3.0562, -2.0231]), tensor([ 2.9957, -2.0440]), tensor([ 1.4512, -1.9797])]\n",
      "[tensor([ 3.1049, -1.9414]), tensor([ 2.6178, -0.9145]), tensor([ 3.0464, -2.0180]), tensor([ 2.9918, -2.0530]), tensor([ 1.5011, -1.9851])]\n",
      "[tensor([ 3.0962, -1.9423]), tensor([ 2.6454, -0.9574]), tensor([ 3.0370, -2.0127]), tensor([ 2.9889, -2.0608]), tensor([ 1.5499, -1.9905])]\n",
      "[tensor([ 3.0876, -1.9439]), tensor([ 2.6717, -0.9991]), tensor([ 3.0281, -2.0074]), tensor([ 2.9869, -2.0676]), tensor([ 1.5976, -1.9957])]\n",
      "[tensor([ 3.0790, -1.9463]), tensor([ 2.6969, -1.0397]), tensor([ 3.0198, -2.0024]), tensor([ 2.9859, -2.0734]), tensor([ 1.6442, -2.0006])]\n",
      "[tensor([ 3.0705, -1.9493]), tensor([ 2.7208, -1.0792]), tensor([ 3.0121, -1.9977]), tensor([ 2.9860, -2.0782]), tensor([ 1.6898, -2.0050])]\n",
      "[tensor([ 3.0623, -1.9528]), tensor([ 2.7435, -1.1176]), tensor([ 3.0049, -1.9936]), tensor([ 2.9869, -2.0822]), tensor([ 1.7343, -2.0089])]\n",
      "[tensor([ 3.0542, -1.9567]), tensor([ 2.7651, -1.1548]), tensor([ 2.9984, -1.9901]), tensor([ 2.9886, -2.0854]), tensor([ 1.7778, -2.0120])]\n",
      "[tensor([ 3.0465, -1.9609]), tensor([ 2.7855, -1.1910]), tensor([ 2.9925, -1.9873]), tensor([ 2.9909, -2.0878]), tensor([ 1.8202, -2.0144])]\n",
      "[tensor([ 3.0391, -1.9653]), tensor([ 2.8049, -1.2260]), tensor([ 2.9872, -1.9852]), tensor([ 2.9936, -2.0894]), tensor([ 1.8616, -2.0161])]\n",
      "[tensor([ 3.0320, -1.9698]), tensor([ 2.8232, -1.2600]), tensor([ 2.9826, -1.9838]), tensor([ 2.9964, -2.0905]), tensor([ 1.9020, -2.0170])]\n",
      "[tensor([ 3.0253, -1.9745]), tensor([ 2.8405, -1.2930]), tensor([ 2.9785, -1.9832]), tensor([ 2.9993, -2.0909]), tensor([ 1.9414, -2.0171])]\n",
      "[tensor([ 3.0190, -1.9790]), tensor([ 2.8568, -1.3249]), tensor([ 2.9751, -1.9833]), tensor([ 3.0019, -2.0907]), tensor([ 1.9798, -2.0166])]\n",
      "[tensor([ 3.0131, -1.9835]), tensor([ 2.8721, -1.3558]), tensor([ 2.9723, -1.9840]), tensor([ 3.0041, -2.0901]), tensor([ 2.0172, -2.0156])]\n",
      "[tensor([ 3.0077, -1.9879]), tensor([ 2.8865, -1.3857]), tensor([ 2.9700, -1.9852]), tensor([ 3.0059, -2.0890]), tensor([ 2.0536, -2.0140])]\n",
      "[tensor([ 3.0027, -1.9920]), tensor([ 2.9000, -1.4146]), tensor([ 2.9683, -1.9868]), tensor([ 3.0070, -2.0875]), tensor([ 2.0891, -2.0120])]\n",
      "[tensor([ 2.9982, -1.9959]), tensor([ 2.9126, -1.4425]), tensor([ 2.9671, -1.9889]), tensor([ 3.0076, -2.0856]), tensor([ 2.1236, -2.0097])]\n",
      "[tensor([ 2.9941, -1.9995]), tensor([ 2.9244, -1.4694]), tensor([ 2.9663, -1.9911]), tensor([ 3.0076, -2.0834]), tensor([ 2.1571, -2.0073])]\n",
      "[tensor([ 2.9904, -2.0027]), tensor([ 2.9354, -1.4955]), tensor([ 2.9660, -1.9935]), tensor([ 3.0071, -2.0809]), tensor([ 2.1897, -2.0048])]\n",
      "[tensor([ 2.9872, -2.0056]), tensor([ 2.9456, -1.5206]), tensor([ 2.9661, -1.9959]), tensor([ 3.0061, -2.0782]), tensor([ 2.2214, -2.0024])]\n",
      "[tensor([ 2.9844, -2.0082]), tensor([ 2.9551, -1.5448]), tensor([ 2.9666, -1.9983]), tensor([ 3.0048, -2.0752]), tensor([ 2.2522, -2.0001])]\n",
      "[tensor([ 2.9820, -2.0103]), tensor([ 2.9639, -1.5681]), tensor([ 2.9674, -2.0004]), tensor([ 3.0032, -2.0721]), tensor([ 2.2821, -1.9980])]\n",
      "[tensor([ 2.9800, -2.0121]), tensor([ 2.9720, -1.5905]), tensor([ 2.9685, -2.0024]), tensor([ 3.0016, -2.0689]), tensor([ 2.3112, -1.9962])]\n",
      "[tensor([ 2.9784, -2.0135]), tensor([ 2.9794, -1.6121]), tensor([ 2.9699, -2.0041]), tensor([ 3.0000, -2.0655]), tensor([ 2.3393, -1.9947])]\n",
      "[tensor([ 2.9771, -2.0145]), tensor([ 2.9863, -1.6329]), tensor([ 2.9714, -2.0055]), tensor([ 2.9986, -2.0621]), tensor([ 2.3666, -1.9936])]\n",
      "[tensor([ 2.9762, -2.0152]), tensor([ 2.9925, -1.6529]), tensor([ 2.9732, -2.0065]), tensor([ 2.9974, -2.0586]), tensor([ 2.3931, -1.9928])]\n",
      "[tensor([ 2.9756, -2.0155]), tensor([ 2.9982, -1.6721]), tensor([ 2.9751, -2.0071]), tensor([ 2.9965, -2.0550]), tensor([ 2.4188, -1.9924])]\n",
      "[tensor([ 2.9753, -2.0156]), tensor([ 3.0033, -1.6905]), tensor([ 2.9771, -2.0074]), tensor([ 2.9959, -2.0515]), tensor([ 2.4436, -1.9924])]\n",
      "[tensor([ 2.9753, -2.0153]), tensor([ 3.0080, -1.7081]), tensor([ 2.9792, -2.0074]), tensor([ 2.9957, -2.0480]), tensor([ 2.4677, -1.9927])]\n",
      "[tensor([ 2.9755, -2.0148]), tensor([ 3.0121, -1.7250]), tensor([ 2.9813, -2.0071]), tensor([ 2.9959, -2.0445]), tensor([ 2.4909, -1.9932])]\n",
      "[tensor([ 2.9759, -2.0141]), tensor([ 3.0159, -1.7412]), tensor([ 2.9834, -2.0065]), tensor([ 2.9963, -2.0410]), tensor([ 2.5134, -1.9940])]\n",
      "[tensor([ 2.9766, -2.0132]), tensor([ 3.0192, -1.7567]), tensor([ 2.9856, -2.0056]), tensor([ 2.9970, -2.0377]), tensor([ 2.5352, -1.9950])]\n",
      "[tensor([ 2.9774, -2.0122]), tensor([ 3.0221, -1.7716]), tensor([ 2.9877, -2.0047]), tensor([ 2.9979, -2.0344]), tensor([ 2.5562, -1.9961])]\n",
      "[tensor([ 2.9784, -2.0110]), tensor([ 3.0246, -1.7857]), tensor([ 2.9897, -2.0036]), tensor([ 2.9988, -2.0312]), tensor([ 2.5765, -1.9973])]\n",
      "[tensor([ 2.9795, -2.0097]), tensor([ 3.0268, -1.7993]), tensor([ 2.9917, -2.0025]), tensor([ 2.9997, -2.0281]), tensor([ 2.5962, -1.9984])]\n",
      "[tensor([ 2.9807, -2.0084]), tensor([ 3.0286, -1.8122]), tensor([ 2.9936, -2.0014]), tensor([ 3.0006, -2.0251]), tensor([ 2.6151, -1.9996])]\n",
      "各初期点からの最適化結果:\n",
      "Start 1: x = (2.9807, -2.0084), loss = 4.0004\n",
      "Start 2: x = (3.0286, -1.8122), loss = 4.0361\n",
      "Start 3: x = (2.9936, -2.0014), loss = 4.0000\n",
      "Start 4: x = (3.0006, -2.0251), loss = 4.0006\n",
      "Start 5: x = (2.6151, -1.9996), loss = 4.1482\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "# 最小化したい関数（例として2次元入力を仮定）\n",
    "def func(x):\n",
    "    return (x[:, 0] - 3) ** 2 + (x[:, 1] + 2) ** 2 + 4\n",
    "\n",
    "# マルチスタートの数と初期点生成\n",
    "n_starts = 5  # マルチスタートの数\n",
    "input_dim = 2  # 入力次元\n",
    "initial_param = torch.tensor([[0.0, 0.0]])  # 指定した初期パラメータ\n",
    "\n",
    "# Sobolエンジンで初期点を生成 (一様分布の区間を [-5, 5] と仮定)\n",
    "sobol_engine = SobolEngine(dimension=input_dim, scramble=True)\n",
    "sobol_points = sobol_engine.draw(n_starts - 1) * 10 - 5  # (n_starts - 1, input_dim)\n",
    "\n",
    "# 指定した初期パラメータを追加して初期点リストを作成し、行列化\n",
    "initial_points = torch.cat((initial_param, sobol_points), dim=0).requires_grad_(True)  # (n_starts, input_dim)\n",
    "\n",
    "# Adamオプティマイザの設定\n",
    "optimizer = optim.Adam([initial_points], lr=0.1)\n",
    "\n",
    "# 最適化ループ\n",
    "n_steps = 100\n",
    "for step in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = func(initial_points).sum()  # 各初期点での損失を計算し合計\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# 最終結果を表示\n",
    "print(\"各初期点からの最適化結果:\")\n",
    "for i, x_opt in enumerate(initial_points, 1):\n",
    "    final_loss = func(x_opt.unsqueeze(0)).item()  # 各点の損失を個別に計算\n",
    "    print(f\"Start {i}: x = ({x_opt[0].item():.4f}, {x_opt[1].item():.4f}), loss = {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
